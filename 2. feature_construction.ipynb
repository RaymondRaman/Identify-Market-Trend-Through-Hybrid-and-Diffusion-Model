{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from sklearn.impute import KNNImputer\n",
    "from general_used_functions import *\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config data\n",
    "config_data = load_config_file()\n",
    "\n",
    "# Load the data from the data directory\n",
    "DATA_DIR = os.getcwd() + '/data'\n",
    "training_stock_df = defaultdict(list)\n",
    "testing_stock_df = defaultdict(list)\n",
    "stock_list = config_data['stock_dict'].keys()\n",
    "\n",
    "# Load traininig data\n",
    "for stock in stock_list:\n",
    "    training_stock_data = pd.read_excel(f\"{DATA_DIR}/stock_price_data/training/{stock}_stock_price_data(training).xlsx\")\n",
    "    training_stock_df[stock] = training_stock_data\n",
    "\n",
    "# Load testing data\n",
    "for stock in stock_list:\n",
    "    testing_stock_data = pd.read_excel(f\"{DATA_DIR}/stock_price_data/testing/{stock}_stock_price_data(testing).xlsx\")\n",
    "    testing_stock_df[stock] = testing_stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature dataframe and store the date as the first column\n",
    "training_feature_df = {}\n",
    "testing_feature_df = {}\n",
    "\n",
    "# Training\n",
    "for stock in stock_list:\n",
    "    training_feature_df[stock] = pd.DataFrame()\n",
    "    training_feature_df[stock]['date'] = training_stock_df[stock]['date']\n",
    "\n",
    "# Testing\n",
    "for stock in stock_list:\n",
    "    testing_feature_df[stock] = pd.DataFrame()\n",
    "    testing_feature_df[stock]['date'] = testing_stock_df[stock]['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 1 - 3: Exponential Weighted Moving (EMW) with halflives(days) = 5, 10 and 21  (Self-Constructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_moving_average(data, halflives):\n",
    "    return data.ewm(halflife=halflives).mean()\n",
    "\n",
    "# Training\n",
    "for stock in stock_list:\n",
    "    for halflife in [5, 10, 21]:\n",
    "        training_feature_df[stock][f'{stock}_exponential_moving_average_{halflife}'] = exponential_moving_average(training_stock_df[stock][stock], halflife)\n",
    "\n",
    "        if check_weird_data(training_feature_df[stock][f'{stock}_exponential_moving_average_{halflife}']):\n",
    "            print(f\"Feature {stock}_exponential_moving_average_{halflife} contains weird data in training data\")\n",
    "\n",
    "# Testing\n",
    "for stock in stock_list:\n",
    "    for halflife in [5, 10, 21]:\n",
    "        testing_feature_df[stock][f'{stock}_exponential_moving_average_{halflife}'] = exponential_moving_average(testing_stock_df[stock][stock], halflife)\n",
    "\n",
    "        if check_weird_data(testing_feature_df[stock][f'{stock}_exponential_moving_average_{halflife}']):\n",
    "            print(f\"Feature {stock}_exponential_moving_average_{halflife} contains weird data in testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 4 - 6: EWM downside deviation (DD) in log scale with halflives(days) = 5, 10, 21 (Self-Constructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_moving_downside_deviation_with_log(data, halflives, TRADING_DAYS=252):\n",
    "    log_returns = np.log(data / data.shift(1))\n",
    "    downside_returns = log_returns[log_returns < 0].fillna(0)\n",
    "    ewm_std = downside_returns.ewm(halflife=halflives).std()\n",
    "    annualized_ewm_std = ewm_std * np.sqrt(TRADING_DAYS)\n",
    "    return annualized_ewm_std\n",
    "\n",
    "# Initialize a dictionary to store weird columns for each stock\n",
    "training_weird_columns_dict = {stock: [] for stock in stock_list}\n",
    "testing_weird_columns_dict = {stock: [] for stock in stock_list}\n",
    "\n",
    "# Training\n",
    "for stock in stock_list:\n",
    "    for halflife in [5, 10, 21]:\n",
    "        downside_deviation = weighted_moving_downside_deviation_with_log(training_stock_df[stock][stock], halflife)\n",
    "        downside_deviation = downside_deviation.reindex(training_stock_df[stock].index) \n",
    "        training_feature_df[stock][f'{stock}_downside_deviation_{halflife}'] = downside_deviation\n",
    "\n",
    "        if check_weird_data(training_feature_df[stock][f'{stock}_downside_deviation_{halflife}']):\n",
    "            print(f\"Feature {stock}_downside_deviation_{halflife} contains weird data\")\n",
    "            training_weird_columns_dict[stock].append(f'{stock}_downside_deviation_{halflife}')\n",
    "\n",
    "# Testing\n",
    "for stock in stock_list:\n",
    "    for halflife in [5, 10, 21]:\n",
    "        downside_deviation = weighted_moving_downside_deviation_with_log(testing_stock_df[stock][stock], halflife)\n",
    "        downside_deviation = downside_deviation.reindex(testing_stock_df[stock].index) \n",
    "        testing_feature_df[stock][f'{stock}_downside_deviation_{halflife}'] = downside_deviation\n",
    "\n",
    "        if check_weird_data(testing_feature_df[stock][f'{stock}_downside_deviation_{halflife}']):\n",
    "            print(f\"Feature {stock}_downside_deviation_{halflife} contains weird data\")\n",
    "            testing_weird_columns_dict[stock].append(f'{stock}_downside_deviation_{halflife}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle the weird data with KNN imputer\n",
    "def handle_weird_data_with_knn_imputer(data, weird_columns):\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    data[weird_columns] = imputer.fit_transform(data[weird_columns])\n",
    "    return data\n",
    "\n",
    "\n",
    "# Training\n",
    "for stock, weird_columns in training_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        training_feature_df[stock] = handle_weird_data_with_knn_imputer(training_feature_df[stock], weird_columns)\n",
    "\n",
    "# Testing\n",
    "for stock, weird_columns in testing_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        testing_feature_df[stock] = handle_weird_data_with_knn_imputer(testing_feature_df[stock], weird_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data again\n",
    "for stock, stock_data in training_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in training data\")\n",
    "\n",
    "for stock, stock_data in testing_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear weird_columns_dict, only clear the value, not the key\n",
    "for stock in stock_list:\n",
    "    training_weird_columns_dict[stock] = []\n",
    "\n",
    "for stock in stock_list:\n",
    "    testing_weird_columns_dict[stock] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 7 - 9: Sortino ratio (Self-Constructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, calculate the daily return of the stock\n",
    "def daily_return(stock_price):\n",
    "    return stock_price.pct_change()\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    stock_data[f'{stock}_daily_return'] = daily_return(stock_data[stock])\n",
    "    if check_weird_data(stock_data[f'{stock}_daily_return']):\n",
    "            print(f\"{stock} daily return contains weird data in training data\")\n",
    "            training_weird_columns_dict[stock].append(f'{stock}_daily_return')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    stock_data[f'{stock}_daily_return'] = daily_return(stock_data[stock])\n",
    "    if check_weird_data(stock_data[f'{stock}_daily_return']):\n",
    "            print(f\"{stock} daily return contains weird data in testing data\")\n",
    "            testing_weird_columns_dict[stock].append(f'{stock}_daily_return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the weird data with KNN imputer\n",
    "# Training\n",
    "for stock, weird_columns in training_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        training_stock_df[stock] = handle_weird_data_with_knn_imputer(training_stock_df[stock], weird_columns)\n",
    "\n",
    "# Testing\n",
    "for stock, weird_columns in testing_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        testing_stock_df[stock] = handle_weird_data_with_knn_imputer(testing_stock_df[stock], weird_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data again\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in training data\")\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear weird_columns_dict\n",
    "for stock in stock_list: \n",
    "    training_weird_columns_dict[stock] = []\n",
    "    testing_weird_columns_dict[stock] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before calculating the Sortino ratio, \n",
    "# we need to append the daily risk free rate and \n",
    "# downside deviation to the stock data\n",
    "\n",
    "daily_risk_free_rate = pd.read_excel(f\"{DATA_DIR}/risk_free_rate/(Fama-French 3 Factors Plus Momentum - Daily Frequency)Risk-Free_Return_Rate.xlsx\")\n",
    "daily_risk_free_rate.rename(columns={'Risk-Free Return Rate (One Month Treasury Bill Rate)': 'daily_risk_free_rate'}, inplace=True)\n",
    "\n",
    "# Handle unmatched date format\n",
    "def parse_dates(date_series):\n",
    "    return pd.to_datetime(date_series, dayfirst=False)\n",
    "\n",
    "daily_risk_free_rate['date'] = parse_dates(daily_risk_free_rate['date'])\n",
    "\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    training_stock_df[stock] = pd.merge(stock_data, daily_risk_free_rate, on='date', how='inner')\n",
    "    for halflife in [5, 10, 21]:\n",
    "        downside_deviation = training_feature_df[stock][['date', f'{stock}_downside_deviation_{halflife}']]\n",
    "        training_stock_df[stock] = pd.merge(training_stock_df[stock], downside_deviation, on='date', how='inner')\n",
    "\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    testing_stock_df[stock] = pd.merge(stock_data, daily_risk_free_rate, on='date', how='inner')\n",
    "    for halflife in [5, 10, 21]:\n",
    "        downside_deviation = testing_feature_df[stock][['date', f'{stock}_downside_deviation_{halflife}']]\n",
    "        testing_stock_df[stock] = pd.merge(testing_stock_df[stock], downside_deviation, on='date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Sortino ratio\n",
    "def sortino_ratio(daily_return, risk_free_rate, downside_deviation):\n",
    "    return (daily_return - risk_free_rate) / downside_deviation\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    for halflife in [5, 10, 21]:\n",
    "        daily_return = stock_data[f'{stock}_daily_return']\n",
    "        risk_free_rate = stock_data['daily_risk_free_rate']\n",
    "        downside_deviation = stock_data[f'{stock}_downside_deviation_{halflife}']\n",
    "        training_feature_df[stock][f'{stock}_sortino_ratio_{halflife}'] = sortino_ratio(daily_return, risk_free_rate, downside_deviation)\n",
    "\n",
    "        if check_weird_data(training_feature_df[stock][f'{stock}_sortino_ratio_{halflife}']):\n",
    "            print(f\"{stock} sortino ratio {halflife} contains weird data in training data\")\n",
    "            training_weird_columns_dict[stock].append(f'{stock}_sortino_ratio_{halflife}')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    for halflife in [5, 10, 21]:\n",
    "        daily_return = stock_data[f'{stock}_daily_return']\n",
    "        risk_free_rate = stock_data['daily_risk_free_rate']\n",
    "        downside_deviation = stock_data[f'{stock}_downside_deviation_{halflife}']\n",
    "        testing_feature_df[stock][f'{stock}_sortino_ratio_{halflife}'] = sortino_ratio(daily_return, risk_free_rate, downside_deviation)\n",
    "\n",
    "        if check_weird_data(testing_feature_df[stock][f'{stock}_sortino_ratio_{halflife}']):\n",
    "            print(f\"{stock} sortino ratio {halflife} contains weird data in testing data\")\n",
    "            testing_weird_columns_dict[stock].append(f'{stock}_sortino_ratio_{halflife}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_stock_df['AAPL'].head().to_string())\n",
    "print(training_stock_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 10: 12 Month Momentum (mom12m) (Self-Constructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_12m(stock_price):\n",
    "    price_1m_ago = stock_price.shift(21)\n",
    "    price_12m_ago = stock_price.shift(252)\n",
    "    return price_1m_ago / price_12m_ago - 1\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    training_feature_df[stock][f'{stock}_mom12m'] = momentum_12m(stock_data[stock])\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_mom12m']):\n",
    "        print(f\"Feature {stock}_mom12m contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_mom12m')\n",
    "\n",
    "# Notice that the testing period is too short to calculate the 12-month momentum\n",
    "# So it will be calculated in later stage if this feature is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for stock, weird_columns in training_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        training_feature_df[stock] = handle_weird_data_with_knn_imputer(training_feature_df[stock], weird_columns)\n",
    "\n",
    "# Check the data again\n",
    "for stock, stock_data in training_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in training data\")\n",
    "\n",
    "# Clear weird_columns_dict\n",
    "for stock in stock_list:\n",
    "    training_weird_columns_dict[stock] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 11: short-term reversal (mom1m) (Self-Constructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_1m(stock_price):\n",
    "    stock_price_1m_ago = stock_price.shift(21)\n",
    "    return stock_price / stock_price_1m_ago - 1\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    training_feature_df[stock][f'{stock}_mom1m'] = momentum_1m(stock_data[stock])\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_mom1m']):\n",
    "        print(f\"Feature {stock}_mom1m contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_mom1m')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    testing_feature_df[stock][f'{stock}_mom1m'] = momentum_1m(stock_data[stock])\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_mom1m']):\n",
    "        print(f\"Feature {stock}_mom1m contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_mom1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for stock, weird_columns in training_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        training_feature_df[stock] = handle_weird_data_with_knn_imputer(training_feature_df[stock], weird_columns)\n",
    "\n",
    "# Testing\n",
    "for stock, weird_columns in testing_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        testing_feature_df[stock] = handle_weird_data_with_knn_imputer(testing_feature_df[stock], weird_columns)\n",
    "\n",
    "# Check the data again\n",
    "for stock, stock_data in training_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in training data\")\n",
    "\n",
    "for stock, stock_data in testing_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear weird_columns_dict, only clear the value, not the key\n",
    "for stock in stock_list:\n",
    "    training_weird_columns_dict[stock] = []\n",
    "\n",
    "for stock in stock_list:\n",
    "    testing_weird_columns_dict[stock] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 12: 6-month momentum (mom6m) (Self-Constructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_6m(stock_price):\n",
    "    stock_price_6m_ago = stock_price.shift(126)\n",
    "    return stock_price / stock_price_6m_ago - 1\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    training_feature_df[stock][f'{stock}_mom6m'] = momentum_6m(stock_data[stock])\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_mom6m']):\n",
    "        print(f\"Feature {stock}_mom6m contains weird data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_mom6m')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    testing_feature_df[stock][f'{stock}_mom6m'] = momentum_6m(stock_data[stock])\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_mom6m']):\n",
    "        print(f\"Feature {stock}_mom6m contains weird data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_mom6m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for stock, weird_columns in training_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        training_feature_df[stock] = handle_weird_data_with_knn_imputer(training_feature_df[stock], weird_columns)\n",
    "\n",
    "# Testing\n",
    "for stock, weird_columns in testing_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        testing_feature_df[stock] = handle_weird_data_with_knn_imputer(testing_feature_df[stock], weird_columns)\n",
    "\n",
    "# Check the data again\n",
    "for stock, stock_data in training_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in training data\")\n",
    "\n",
    "for stock, stock_data in testing_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear weird_columns_dict, only clear the value, not the key\n",
    "for stock in stock_list:\n",
    "    training_weird_columns_dict[stock] = []\n",
    "\n",
    "for stock in stock_list:\n",
    "    testing_weird_columns_dict[stock] = []\n",
    "\n",
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 14: Log Market Equity (mvel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Notice that we already have the daily price data,\n",
    "and I found shareoutstanding data can be found on wrds, shrout is the number of shares outstanding\n",
    "https://wrds-www.wharton.upenn.edu/pages/get-data/center-research-security-prices-crsp/annual-update/stock-events/share-outstanding/\n",
    "PERMNO is the unique identifier for each stock\n",
    "AMZN: 84788\n",
    "GOOGL: 90319\n",
    "MSFT: 10107\n",
    "NVDA: 86580\n",
    "AAPL: 14593\n",
    "NFLX: 89393\n",
    "AVGO: 93002\n",
    "TSLA: 93436\n",
    "META: 13407\n",
    "'''\n",
    "permno_dict = config_data['permno_dict']\n",
    "def share_outstanding_preprocessing():\n",
    "    # Load the share outstanding data\n",
    "    share_outstanding_data = pd.read_excel(f\"{DATA_DIR}/company_fundamentals/{stock}_share_outstanding_raw.xlsx\")\n",
    "\n",
    "    # Make sure the downloaded data is correct\n",
    "    if int(permno_dict[stock]) != int(share_outstanding_data['PERMNO'][0]):\n",
    "        print(\"You downloaded the wrong data for {stock}\")\n",
    "        exit()\n",
    "\n",
    "    # rename the column from Shares Observation Date to date\n",
    "    share_outstanding_data = share_outstanding_data.rename(columns={'Shares Observation Date': 'date'})\n",
    "    # Convert the date column to datetime\n",
    "    share_outstanding_data['date'] =  parse_dates(share_outstanding_data['date'])\n",
    "    # Drop PERMNO column\n",
    "    share_outstanding_data = share_outstanding_data.drop(columns=['PERMNO'])\n",
    "    # Notice that the original data is expressed in thousand, so need to multiple the data by 1000\n",
    "    share_outstanding_data['Shares Outstanding'] *= 1000\n",
    "\n",
    "    return share_outstanding_data\n",
    "\n",
    "def mvel1(stock_price, share_outstanding):\n",
    "    return np.log(stock_price * share_outstanding + 1e-9)\n",
    "\n",
    "# Share outstanding data (Training)\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    share_outstanding_data = share_outstanding_preprocessing()\n",
    "    # Merge the share outstanding data with the stock price data (Training)\n",
    "    training_date = parse_dates(training_stock_df[stock]['date'])\n",
    "    training_share_outstanding = pd.merge(training_date, share_outstanding_data, on='date', how='outer')\n",
    "\n",
    "    # Backfill the share outstanding data\n",
    "    training_share_outstanding = training_share_outstanding.bfill()\n",
    "\n",
    "    training_feature_df[stock][f'{stock}_mvel1'] = mvel1(stock_data[stock], training_share_outstanding['Shares Outstanding'])\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_mvel1']):\n",
    "        print(f\"Feature {stock}_mvel1 contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_mvel1')\n",
    "\n",
    "# Share outstanding data (Testing)\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    # Merge the share outstanding data with the stock price data (Testing)\n",
    "    testing_date = parse_dates(testing_stock_df[stock]['date'])\n",
    "    testing_share_outstanding = pd.merge(testing_date, share_outstanding_data, on='date', how='outer')\n",
    "\n",
    "    # Backfill the share outstanding data\n",
    "    testing_share_outstanding = testing_share_outstanding.bfill()\n",
    "\n",
    "    # There are still some missing data in the share outstanding data\n",
    "    # So we need to forward fill the data\n",
    "    testing_share_outstanding = testing_share_outstanding.ffill()\n",
    "\n",
    "    testing_feature_df[stock][f'{stock}_mvel1'] = mvel1(stock_data[stock], testing_share_outstanding['Shares Outstanding'])\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_mvel1']):\n",
    "        print(f\"Feature {stock}_mvel1 contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_mvel1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 15: Standard deviation of daily returns from month t-1 (retvol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Source: https://wrds-www.wharton.upenn.edu/pages/get-data/contributed-data-forms/global-factor-data/\n",
    "PERMNO is the unique identifier for each stock\n",
    "Amazon: 84788\n",
    "Google: 90319\n",
    "Microsoft: 10107\n",
    "Nvidia: 86580\n",
    "Apple: 14593\n",
    "NFLX: 89393\n",
    "AVGO: 93002\n",
    "Tesla: 93436\n",
    "Meta: 13407\n",
    "\"\"\"\n",
    "def get_rvol_21d(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_col = ['Day of last price observation (date)', 'Return volatility (rvol_21d)']\n",
    "    rvol_21d = global_factor[target_col].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Rename the columns\n",
    "    rvol_21d.rename(columns={'Return volatility (rvol_21d)': f'{stock}_rvol_21d'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    rvol_21d['Day of last price observation (date)'] = parse_dates(rvol_21d['Day of last price observation (date)'])\n",
    "\n",
    "    return rvol_21d\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    rvol_21d = get_rvol_21d(stock)\n",
    "\n",
    "    # Merge the rvol_21d data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], rvol_21d, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values \n",
    "    training_feature_df[stock][f'{stock}_rvol_21d'] = training_feature_df[stock][f'{stock}_rvol_21d'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_rvol_21d']):\n",
    "        print(f\"Feature f'{stock}_rvol_21d' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_rvol_21d')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    rvol_21d = get_rvol_21d(stock)\n",
    "\n",
    "    # Merge the rvol_21d data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], rvol_21d, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_rvol_21d'] = testing_feature_df[stock][f'{stock}_rvol_21d'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_rvol_21d']):\n",
    "        print(f\"Feature f'{stock}_rvol_21d' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_rvol_21d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 16-18: Change in Shares - 1 Month (chcsho_1m, chcsho_3m, chcsho_6m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chcsho(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Change in Shares - 1 Month (chcsho_1m)', 'Change in Shares - 3 Month (chcsho_3m)', 'Change in Shares - 6 Month (chcsho_6m)']\n",
    "    chcsho = global_factor[target_cols].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Rename the columns\n",
    "    chcsho.rename(columns={'Change in Shares - 1 Month (chcsho_1m)': f'{stock}_chcsho_1m', 'Change in Shares - 3 Month (chcsho_3m)': f'{stock}_chcsho_3m', 'Change in Shares - 6 Month (chcsho_6m)': f'{stock}_chcsho_6m'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    chcsho['Day of last price observation (date)'] = parse_dates(chcsho['Day of last price observation (date)'])\n",
    "\n",
    "    return chcsho\n",
    "\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    chcsho = get_chcsho(stock)\n",
    "\n",
    "    # Merge the chcsho data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], chcsho, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_chcsho_1m'] = training_feature_df[stock][f'{stock}_chcsho_1m'].bfill()\n",
    "    training_feature_df[stock][f'{stock}_chcsho_3m'] = training_feature_df[stock][f'{stock}_chcsho_3m'].bfill()\n",
    "    training_feature_df[stock][f'{stock}_chcsho_6m'] = training_feature_df[stock][f'{stock}_chcsho_6m'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_chcsho_1m']):\n",
    "        print(f\"Feature f'{stock}_chcsho_1m' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_chcsho_1m')\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_chcsho_3m']):\n",
    "        print(f\"Feature f'{stock}_chcsho_3m' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_chcsho_3m')\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_chcsho_6m']):\n",
    "        print(f\"Feature f'{stock}_chcsho_6m' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_chcsho_6m')\n",
    "\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    chcsho = get_chcsho(stock)\n",
    "\n",
    "    # Merge the chcsho data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], chcsho, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_chcsho_1m'] = testing_feature_df[stock][f'{stock}_chcsho_1m'].bfill()\n",
    "    testing_feature_df[stock][f'{stock}_chcsho_3m'] = testing_feature_df[stock][f'{stock}_chcsho_3m'].bfill()\n",
    "    testing_feature_df[stock][f'{stock}_chcsho_6m'] = testing_feature_df[stock][f'{stock}_chcsho_6m'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_chcsho_1m']):\n",
    "        print(f\"Feature f'{stock}_chcsho_1m' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_chcsho_1m')\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_chcsho_3m']):\n",
    "        print(f\"Feature f'{stock}_chcsho_3m' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_chcsho_3m')\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_chcsho_6m']):\n",
    "        print(f\"Feature f'{stock}_chcsho_6m' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_chcsho_6m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 19: Amihud illiquidity (ami_126d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ami_126d(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Amihud Measure (ami_126d)']\n",
    "    ami_126d = global_factor[target_cols].copy()\n",
    "    \n",
    "\n",
    "    # Rename the columns\n",
    "    ami_126d.rename(columns={'Amihud Measure (ami_126d)': f'{stock}_ami_126d'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    ami_126d['Day of last price observation (date)'] = parse_dates(ami_126d['Day of last price observation (date)'])\n",
    "\n",
    "    return ami_126d\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    ami_126d = get_ami_126d(stock)\n",
    "\n",
    "    # Merge the ami_126d data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], ami_126d, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_ami_126d'] = training_feature_df[stock][f'{stock}_ami_126d'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_ami_126d']):\n",
    "        print(f\"Feature f'{stock}_ami_126d' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_ami_126d')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    ami_126d = get_ami_126d(stock)\n",
    "\n",
    "    # Merge the ami_126d data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], ami_126d, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_ami_126d'] = testing_feature_df[stock][f'{stock}_ami_126d'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_ami_126d']):\n",
    "        print(f\"Feature f'{stock}_ami_126d' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_ami_126d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 20: Age of the firms in months (age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Firm age (age)']\n",
    "    age = global_factor[target_cols].copy()\n",
    "    \n",
    "\n",
    "    # Rename the columns\n",
    "    age.rename(columns={'Firm age (age)': f'{stock}_age'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    age['Day of last price observation (date)'] = parse_dates(age['Day of last price observation (date)'])\n",
    "\n",
    "    return age\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    age = get_age(stock)\n",
    "\n",
    "    # Merge the age data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], age, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_age'] = training_feature_df[stock][f'{stock}_age'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_age']):\n",
    "        print(f\"Feature f'{stock}_age' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_age')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    age = get_age(stock)\n",
    "\n",
    "    # Merge the age data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], age, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_age'] = testing_feature_df[stock][f'{stock}_age'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_age']):\n",
    "        print(f\"Feature f'{stock}_age' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 21: Change in 6-month momentum (chmom) (Self-Constructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chmom(stock_price):\n",
    "    price_1m_ago = stock_price.shift(21)\n",
    "    price_6m_ago = stock_price.shift(126)\n",
    "\n",
    "    price_7m_ago = stock_price.shift(147)\n",
    "    price_12m_ago = stock_price.shift(252)\n",
    "    return (price_1m_ago / price_6m_ago) - 1 - ( (price_7m_ago / price_12m_ago) - 1 )\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    training_feature_df[stock][f'{stock}_chmom'] = get_chmom(stock_data[stock])\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_chmom']):\n",
    "        print(f\"Feature {stock}_chmom contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_chmom')\n",
    "\n",
    "# Similarly, the testing period is too short to calculate the change in 6-month momentum\n",
    "# So it will be calculated in later stage if this feature is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for stock, weird_columns in training_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        training_feature_df[stock] = handle_weird_data_with_knn_imputer(training_feature_df[stock], weird_columns)\n",
    "\n",
    "# Check the data again\n",
    "for stock, stock_data in training_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear weird_columns_dict, only clear the value, not the key\n",
    "for stock in stock_list:\n",
    "    training_weird_columns_dict[stock] = []\n",
    "\n",
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 22: Maximum daily return (maxret) (Self-Constructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxret(stock_df, stock_ticket):\n",
    "    # Create a copy to avoid SettingWithCopy issues\n",
    "    df = stock_df.copy()\n",
    "    df.loc[:, 'year_month'] = df['date'].dt.to_period('M')\n",
    "    monthly_max = df.groupby('year_month')[f'{stock_ticket}_daily_return'].max().reset_index()\n",
    "    # Rename the computed column\n",
    "    monthly_max = monthly_max.rename(columns={f'{stock_ticket}_daily_return': f'{stock_ticket}_maxret'})\n",
    "    # Shift the max returns down by one period so that each row corresponds to calendar month t-1\n",
    "    monthly_max[f'{stock_ticket}_maxret'] = monthly_max[f'{stock_ticket}_maxret'].shift(1)\n",
    "    # Convert the period back to a timestamp; here we choose the month-end timestamp\n",
    "    monthly_max['year_month'] = monthly_max['year_month'].dt.to_timestamp('M')\n",
    "    return monthly_max\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    maxret = get_maxret(stock_data, stock)\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], maxret, how='left', left_on='date', right_on='year_month')\n",
    "    training_feature_df[stock].drop(columns=['year_month'], inplace=True)\n",
    "    training_feature_df[stock][f'{stock}_maxret'] = training_feature_df[stock][f'{stock}_maxret'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_maxret']):\n",
    "        print(f\"Feature {stock}_maxret contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_maxret')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    maxret = get_maxret(stock_data, stock)\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], maxret, how='left', left_on='date', right_on='year_month')\n",
    "    testing_feature_df[stock].drop(columns=['year_month'], inplace=True)\n",
    "    testing_feature_df[stock][f'{stock}_maxret'] = testing_feature_df[stock][f'{stock}_maxret'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_maxret']):\n",
    "        print(f\"Feature {stock}_maxret contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_maxret')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for stock, weird_columns in training_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        training_feature_df[stock] = handle_weird_data_with_knn_imputer(training_feature_df[stock], weird_columns)\n",
    "\n",
    "# Testing\n",
    "for stock, weird_columns in testing_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        testing_feature_df[stock] = handle_weird_data_with_knn_imputer(testing_feature_df[stock], weird_columns)\n",
    "\n",
    "# Check the data again\n",
    "for stock, stock_data in training_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in training data\")\n",
    "\n",
    "for stock, stock_data in testing_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in testing data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear weird_columns_dict, only clear the value, not the key\n",
    "for stock in stock_list:\n",
    "    training_weird_columns_dict[stock] = []\n",
    "\n",
    "for stock in stock_list:\n",
    "    testing_weird_columns_dict[stock] = []\n",
    "\n",
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 23: Dollar trading volume (dolvol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dolvol(stock):\n",
    "    gobal_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Dollar trading volume (dolvol)']\n",
    "    dolvol = gobal_factor[target_cols].copy()\n",
    "    \n",
    "    # Rename the columns\n",
    "    dolvol.rename(columns={'Dollar trading volume (dolvol)': f'{stock}_dolvol'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    dolvol['Day of last price observation (date)'] = parse_dates(dolvol['Day of last price observation (date)'])\n",
    "\n",
    "    return dolvol\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    dolvol = get_dolvol(stock)\n",
    "\n",
    "    # Merge the dolvol data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], dolvol, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_dolvol'] = training_feature_df[stock][f'{stock}_dolvol'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_dolvol']):\n",
    "        print(f\"Feature f'{stock}_dolvol' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_dolvol')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    dolvol = get_dolvol(stock)\n",
    "\n",
    "    # Merge the dolvol data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], dolvol, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_dolvol'] = testing_feature_df[stock][f'{stock}_dolvol'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_dolvol']):\n",
    "        print(f\"Feature f'{stock}_dolvol' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_dolvol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 24: 60 Month CAPM Beta (beta_60m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta_60m(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Market Beta (beta_60m)']\n",
    "    beta_60m = global_factor[target_cols].copy()\n",
    "    \n",
    "\n",
    "    # Rename the columns\n",
    "    beta_60m.rename(columns={'Market Beta (beta_60m)': f'{stock}_beta_60m'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    beta_60m['Day of last price observation (date)'] = parse_dates(beta_60m['Day of last price observation (date)'])\n",
    "\n",
    "    return beta_60m\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    beta_60m = get_beta_60m(stock)\n",
    "\n",
    "    # Merge the beta_60m data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], beta_60m, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_beta_60m'] = training_feature_df[stock][f'{stock}_beta_60m'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_beta_60m']):\n",
    "        print(f\"Feature f'{stock}_beta_60m' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_beta_60m')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    beta_60m = get_beta_60m(stock)\n",
    "\n",
    "    # Merge the beta_60m data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], beta_60m, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_beta_60m'] = testing_feature_df[stock][f'{stock}_beta_60m'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_beta_60m']):\n",
    "        print(f\"Feature f'{stock}_beta_60m' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_beta_60m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 25-27: Number of zero trades with turnover as tiebreaker (1 month, 6 months, 12 months) (zero_trades_21d, zero_trades_126d, zero_trades_252d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_trades(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Number of zero trades with turnover as tiebreaker (1 month) (ze', 'Number of zero trades with turnover as tiebreaker (6 months) (z', 'Number of zero trades with turnover as tiebreaker (12 months) (' ]\n",
    "    zero_trades = global_factor[target_cols].copy()\n",
    "    \n",
    "\n",
    "    # Rename the columns\n",
    "    zero_trades.rename(columns={\n",
    "        'Number of zero trades with turnover as tiebreaker (1 month) (ze': f'{stock}_zero_trades_1m', \n",
    "        'Number of zero trades with turnover as tiebreaker (6 months) (z': f'{stock}_zero_trades_6m', \n",
    "        'Number of zero trades with turnover as tiebreaker (12 months) (': f'{stock}_zero_trades_12m'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    zero_trades['Day of last price observation (date)'] = parse_dates(zero_trades['Day of last price observation (date)'])\n",
    "\n",
    "    return zero_trades\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    zero_trades = get_zero_trades(stock)\n",
    "\n",
    "    # Merge the zero_trades data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], zero_trades, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_zero_trades_1m'] = training_feature_df[stock][f'{stock}_zero_trades_1m'].bfill()\n",
    "    training_feature_df[stock][f'{stock}_zero_trades_6m'] = training_feature_df[stock][f'{stock}_zero_trades_6m'].bfill()\n",
    "    training_feature_df[stock][f'{stock}_zero_trades_12m'] = training_feature_df[stock][f'{stock}_zero_trades_12m'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_zero_trades_1m']):\n",
    "        print(f\"Feature f'{stock}_zero_trades_1m' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_zero_trades_1m')\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_zero_trades_6m']):\n",
    "        print(f\"Feature f'{stock}_zero_trades_6m' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_zero_trades_6m')\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_zero_trades_12m']):\n",
    "        print(f\"Feature f'{stock}_zero_trades_12m' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_zero_trades_12m')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    zero_trades = get_zero_trades(stock)\n",
    "\n",
    "    # Merge the zero_trades data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], zero_trades, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_zero_trades_1m'] = testing_feature_df[stock][f'{stock}_zero_trades_1m'].bfill()\n",
    "    testing_feature_df[stock][f'{stock}_zero_trades_6m'] = testing_feature_df[stock][f'{stock}_zero_trades_6m'].bfill()\n",
    "    testing_feature_df[stock][f'{stock}_zero_trades_12m'] = testing_feature_df[stock][f'{stock}_zero_trades_12m'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_zero_trades_1m']):\n",
    "        print(f\"Feature f'{stock}_zero_trades_1m' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_zero_trades_1m')\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_zero_trades_6m']):\n",
    "        print(f\"Feature f'{stock}_zero_trades_6m' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_zero_trades_6m')\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_zero_trades_12m']):\n",
    "        print(f\"Feature f'{stock}_zero_trades_12m' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_zero_trades_12m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 13: Frazzini-Pedersen market beta (betabab_1260d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_betabab_1260d(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Frazzini-Pedersen market beta (betabab_1260d)']\n",
    "    betabab_1260d = global_factor[target_cols].copy()\n",
    "    \n",
    "\n",
    "    # Rename the columns\n",
    "    betabab_1260d.rename(columns={'Frazzini-Pedersen market beta (betabab_1260d)': f'{stock}_betabab_1260d'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    betabab_1260d['Day of last price observation (date)'] = parse_dates(betabab_1260d['Day of last price observation (date)'])\n",
    "\n",
    "    return betabab_1260d\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    betabab_1260d = get_betabab_1260d(stock)\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], betabab_1260d, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_betabab_1260d'] = training_feature_df[stock][f'{stock}_betabab_1260d'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_betabab_1260d']):\n",
    "        print(f\"Feature f'{stock}_betabab_1260d' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_betabab_1260d')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    betabab_1260d = get_betabab_1260d(stock)\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], betabab_1260d, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_betabab_1260d'] = testing_feature_df[stock][f'{stock}_betabab_1260d'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_betabab_1260d']):\n",
    "        print(f\"Feature f'{stock}_betabab_1260d' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_betabab_1260d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 26: Earnings variability (earnings_variability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earnings_variability(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Earnings variability (earnings_variability)']\n",
    "    earnings_variability = global_factor[target_cols].copy()\n",
    "\n",
    "    # Rename the columns\n",
    "    earnings_variability.rename(columns={'Earnings variability (earnings_variability)': f'{stock}_earnings_variability'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    earnings_variability['Day of last price observation (date)'] = parse_dates(earnings_variability['Day of last price observation (date)'])\n",
    "\n",
    "    return earnings_variability\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    earnings_variability = get_earnings_variability(stock)\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], earnings_variability, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_earnings_variability'] = training_feature_df[stock][f'{stock}_earnings_variability'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_earnings_variability']):\n",
    "        print(f\"Feature f'{stock}_earnings_variability' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_earnings_variability')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    earnings_variability = get_earnings_variability(stock)\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], earnings_variability, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_earnings_variability'] = testing_feature_df[stock][f'{stock}_earnings_variability'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_earnings_variability']):\n",
    "        print(f\"Feature f'{stock}_earnings_variability' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_earnings_variability')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 27: Operating Cash Flow to Sales Quarterly Volatility (ocfq_saleq_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocfq_saleq_std(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Cash flow volatility (ocfq_saleq_std)']\n",
    "    ocfq_saleq_std = global_factor[target_cols].copy()\n",
    "\n",
    "    # Rename the columns\n",
    "    ocfq_saleq_std.rename(columns={'Cash flow volatility (ocfq_saleq_std)': f'{stock}_ocfq_saleq_std'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    ocfq_saleq_std['Day of last price observation (date)'] = parse_dates(ocfq_saleq_std['Day of last price observation (date)'])\n",
    "\n",
    "    return ocfq_saleq_std\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    ocfq_saleq_std = get_ocfq_saleq_std(stock)\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], ocfq_saleq_std, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_ocfq_saleq_std'] = training_feature_df[stock][f'{stock}_ocfq_saleq_std'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_ocfq_saleq_std']):\n",
    "        print(f\"Feature f'{stock}_ocfq_saleq_std' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_ocfq_saleq_std')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    ocfq_saleq_std = get_ocfq_saleq_std(stock)\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], ocfq_saleq_std, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_ocfq_saleq_std'] = testing_feature_df[stock][f'{stock}_ocfq_saleq_std'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_ocfq_saleq_std']):\n",
    "        print(f\"Feature f'{stock}_ocfq_saleq_std' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_ocfq_saleq_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 28: Turnover (turnover_126d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turnover_126d(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Share turnover (turnover_126d)']\n",
    "    turnover_126d = global_factor[target_cols].copy()\n",
    "\n",
    "    # Rename the columns\n",
    "    turnover_126d.rename(columns={'Share turnover (turnover_126d)': f'{stock}_turnover_126d'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    turnover_126d['Day of last price observation (date)'] = parse_dates(turnover_126d['Day of last price observation (date)'])\n",
    "\n",
    "    return turnover_126d\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    turnover_126d = get_turnover_126d(stock)\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], turnover_126d, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_turnover_126d'] = training_feature_df[stock][f'{stock}_turnover_126d'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_turnover_126d']):\n",
    "        print(f\"Feature f'{stock}_turnover_126d' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_turnover_126d')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    turnover_126d = get_turnover_126d(stock)\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], turnover_126d, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_turnover_126d'] = testing_feature_df[stock][f'{stock}_turnover_126d'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_turnover_126d']):\n",
    "        print(f\"Feature f'{stock}_turnover_126d' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_turnover_126d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 29: Current price to high price over last year (prc_highprc_252d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prc_highprc_252d(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Current price to high price over last year (prc_highprc_252d)']\n",
    "    prc_highprc_252d = global_factor[target_cols].copy()\n",
    "\n",
    "    # Rename the columns\n",
    "    prc_highprc_252d.rename(columns={target_cols[1]: f'{stock}_prc_highprc_252d'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    prc_highprc_252d[target_cols[0]] = parse_dates(prc_highprc_252d[target_cols[0]])\n",
    "\n",
    "    return prc_highprc_252d\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    prc_highprc_252d = get_prc_highprc_252d(stock)\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], prc_highprc_252d, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}_prc_highprc_252d'] = training_feature_df[stock][f'{stock}_prc_highprc_252d'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_prc_highprc_252d']):\n",
    "        print(f\"Feature f'{stock}_prc_highprc_252d' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_prc_highprc_252d')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    prc_highprc_252d = get_prc_highprc_252d(stock)\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], prc_highprc_252d, how='left', left_on='date', right_on='Day of last price observation (date)')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=['Day of last price observation (date)'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}_prc_highprc_252d'] = testing_feature_df[stock][f'{stock}_prc_highprc_252d'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}_prc_highprc_252d']):\n",
    "        print(f\"Feature f'{stock}_prc_highprc_252d' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}_prc_highprc_252d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 30: Residual momentum t-6 to t-1 (resff3_6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resff3_6_1(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Residual momentum t-6 to t-1 (resff3_6_1)']\n",
    "    new_cols = global_factor[target_cols].copy()\n",
    "\n",
    "    # Rename the columns\n",
    "    new_cols.rename(columns={target_cols[1]: f'{stock}_resff3_6_1'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    new_cols[target_cols[0]] = parse_dates(new_cols[target_cols[0]])\n",
    "\n",
    "    return new_cols\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    new_cols = get_resff3_6_1(stock)\n",
    "    substring = '_resff3_6_1'\n",
    "    date_substring = 'Day of last price observation (date)'\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], new_cols, how='left', left_on='date', right_on=f'{date_substring}')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=[f'{date_substring}'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}{substring}'] = training_feature_df[stock][f'{stock}{substring}'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}{substring}']):\n",
    "        print(f\"Feature f'{stock}{substring}' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}{substring}')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    new_cols = get_resff3_6_1(stock)\n",
    "    substring = '_resff3_6_1'\n",
    "    date_substring = 'Day of last price observation (date)'\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], new_cols, how='left', left_on='date', right_on=f'{date_substring}')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=[f'{date_substring}'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}{substring}'] = testing_feature_df[stock][f'{stock}{substring}'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}{substring}']):\n",
    "        print(f\"Feature f'{stock}{substring}' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}{substring}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 31: 1 Year Non-Annual Seasonality (seas_1_1na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seas_1_1na(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Year 1-lagged return, annual (seas_1_1an)']\n",
    "    new_cols = global_factor[target_cols].copy()\n",
    "\n",
    "    # Rename the columns\n",
    "    new_cols.rename(columns={target_cols[1]: f'{stock}_seas_1_1na'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    new_cols[target_cols[0]] = parse_dates(new_cols[target_cols[0]])\n",
    "\n",
    "    return new_cols\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    new_cols = get_seas_1_1na(stock)\n",
    "    substring = '_seas_1_1na'\n",
    "    date_substring = 'Day of last price observation (date)'\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], new_cols, how='left', left_on='date', right_on=f'{date_substring}')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=[f'{date_substring}'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}{substring}'] = training_feature_df[stock][f'{stock}{substring}'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}{substring}']):\n",
    "        print(f\"Feature f'{stock}{substring}' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}{substring}')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    new_cols = get_seas_1_1na(stock)\n",
    "    substring = '_seas_1_1na'\n",
    "    date_substring = 'Day of last price observation (date)'\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], new_cols, how='left', left_on='date', right_on=f'{date_substring}')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=[f'{date_substring}'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}{substring}'] = testing_feature_df[stock][f'{stock}{substring}'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}{substring}']):\n",
    "        print(f\"Feature f'{stock}{substring}' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}{substring}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 32: Capital turnover (at_turnover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_at_turnover(stock):\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/global_factor/{stock}_global_factor.xlsx\")\n",
    "    target_cols = ['Day of last price observation (date)', 'Capital turnover (at_turnover)']\n",
    "    new_cols = global_factor[target_cols].copy()\n",
    "\n",
    "    # Rename the columns\n",
    "    new_cols.rename(columns={target_cols[1]: f'{stock}_at_turnover'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    new_cols[target_cols[0]] = parse_dates(new_cols[target_cols[0]])\n",
    "\n",
    "    return new_cols\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    new_cols = get_at_turnover(stock)\n",
    "    substring = '_at_turnover'\n",
    "    date_substring = 'Day of last price observation (date)'\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], new_cols, how='left', left_on='date', right_on=f'{date_substring}')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=[f'{date_substring}'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{stock}{substring}'] = training_feature_df[stock][f'{stock}{substring}'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}{substring}']):\n",
    "        print(f\"Feature f'{stock}{substring}' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}{substring}')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    new_cols = get_at_turnover(stock)\n",
    "    substring = '_at_turnover'\n",
    "    date_substring = 'Day of last price observation (date)'\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], new_cols, how='left', left_on='date', right_on=f'{date_substring}')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=[f'{date_substring}'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{stock}{substring}'] = testing_feature_df[stock][f'{stock}{substring}'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{stock}{substring}']):\n",
    "        print(f\"Feature f'{stock}{substring}' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{stock}{substring}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 33: US 30 Day Bill Returns (T-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_T_30():\n",
    "    global_factor = pd.read_excel(f\"{DATA_DIR}/Monetary and Market Condition/US 30 Day Bill Returns.xlsx\")\n",
    "    target_cols = ['Calendar Date', '30 Day Bill Returns']\n",
    "    new_cols = global_factor[target_cols].copy()\n",
    "\n",
    "    # Rename the columns\n",
    "    new_cols.rename(columns={target_cols[1]: f'T_30'}, inplace=True)\n",
    "\n",
    "    # Parse the date column\n",
    "    new_cols[target_cols[0]] = parse_dates(new_cols[target_cols[0]])\n",
    "\n",
    "    return new_cols\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    new_cols = get_T_30()\n",
    "    substring = 'T_30'\n",
    "    date_substring = 'Calendar Date'\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    training_feature_df[stock] = pd.merge(training_feature_df[stock], new_cols, how='left', left_on='date', right_on=f'{date_substring}')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    training_feature_df[stock].drop(columns=[f'{date_substring}'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    training_feature_df[stock][f'{substring}'] = training_feature_df[stock][f'{substring}'].bfill()\n",
    "\n",
    "    if check_weird_data(training_feature_df[stock][f'{substring}']):\n",
    "        print(f\"Feature f'{substring}' contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{substring}')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    new_cols = get_T_30()\n",
    "    substring = 'T_30'\n",
    "    date_substring = 'Calendar Date'\n",
    "\n",
    "    # Merge the data with the stock data\n",
    "    testing_feature_df[stock] = pd.merge(testing_feature_df[stock], new_cols, how='left', left_on='date', right_on=f'{date_substring}')\n",
    "    # Drop the 'Day of last price observation (date)' column\n",
    "    testing_feature_df[stock].drop(columns=[f'{date_substring}'], inplace=True)\n",
    "\n",
    "    # Backfill the missing values\n",
    "    testing_feature_df[stock][f'{substring}'] = testing_feature_df[stock][f'{substring}'].bfill()\n",
    "\n",
    "    if check_weird_data(testing_feature_df[stock][f'{substring}']):\n",
    "        print(f\"Feature f'{substring}' contains weird data in testing data\")\n",
    "        testing_weird_columns_dict[stock].append(f'{substring}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
