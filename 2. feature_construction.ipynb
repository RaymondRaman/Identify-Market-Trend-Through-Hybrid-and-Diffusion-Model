{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from sklearn.impute import KNNImputer\n",
    "from general_used_functions import *\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config data\n",
    "config_data = load_config_file()\n",
    "\n",
    "# Load the data from the data directory\n",
    "DATA_DIR = os.getcwd() + '/data'\n",
    "training_stock_df = defaultdict(list)\n",
    "testing_stock_df = defaultdict(list)\n",
    "stock_list = config_data['stock_dict'].keys()\n",
    "\n",
    "# Load traininig data\n",
    "for stock in stock_list:\n",
    "    training_stock_data = pd.read_excel(f\"{DATA_DIR}/stock_price_data/training/{stock}_stock_price_data(training).xlsx\")\n",
    "    training_stock_df[stock] = training_stock_data\n",
    "\n",
    "# Load testing data\n",
    "for stock in stock_list:\n",
    "    testing_stock_data = pd.read_excel(f\"{DATA_DIR}/stock_price_data/testing/{stock}_stock_price_data(testing).xlsx\")\n",
    "    testing_stock_df[stock] = testing_stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature dataframe and store the date as the first column\n",
    "training_feature_df = {}\n",
    "testing_feature_df = {}\n",
    "\n",
    "# Training\n",
    "for stock in stock_list:\n",
    "    training_feature_df[stock] = pd.DataFrame()\n",
    "    training_feature_df[stock]['date'] = training_stock_df[stock]['date']\n",
    "\n",
    "# Testing\n",
    "for stock in stock_list:\n",
    "    testing_feature_df[stock] = pd.DataFrame()\n",
    "    testing_feature_df[stock]['date'] = testing_stock_df[stock]['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 1 - 3: Exponential Weighted Moving (EMW) with halflives(days) = 5, 10 and 21 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_moving_average(data, halflives):\n",
    "    return data.ewm(halflife=halflives).mean()\n",
    "\n",
    "# Training\n",
    "for stock in stock_list:\n",
    "    for halflife in [5, 10, 21]:\n",
    "        training_feature_df[stock][f'{stock}_exponential_moving_average_{halflife}'] = exponential_moving_average(training_stock_df[stock][stock], halflife)\n",
    "\n",
    "        if check_weird_data(training_feature_df[stock][f'{stock}_exponential_moving_average_{halflife}']):\n",
    "            print(f\"Feature {stock}_exponential_moving_average_{halflife} contains weird data in training data\")\n",
    "\n",
    "# Testing\n",
    "for stock in stock_list:\n",
    "    for halflife in [5, 10, 21]:\n",
    "        testing_feature_df[stock][f'{stock}_exponential_moving_average_{halflife}'] = exponential_moving_average(testing_stock_df[stock][stock], halflife)\n",
    "\n",
    "        if check_weird_data(testing_feature_df[stock][f'{stock}_exponential_moving_average_{halflife}']):\n",
    "            print(f\"Feature {stock}_exponential_moving_average_{halflife} contains weird data in testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  AAPL_exponential_moving_average_5  AAPL_exponential_moving_average_10  AAPL_exponential_moving_average_21\n",
      "0 2016-07-01                          23.972500                           23.972500                           23.972500\n",
      "1 2016-07-05                          23.852214                           23.856102                           23.858143\n",
      "2 2016-07-06                          23.863737                           23.865518                           23.866531\n",
      "3 2016-07-07                          23.900616                           23.898562                           23.897631\n",
      "4 2016-07-08                          23.970359                           23.960624                           23.955759\n",
      "        date  AAPL_exponential_moving_average_5  AAPL_exponential_moving_average_10  AAPL_exponential_moving_average_21\n",
      "0 2024-01-02                         185.639999                          185.639999                          185.639999\n",
      "1 2024-01-03                         184.896903                          184.920922                          184.933531\n",
      "2 2024-01-04                         183.760512                          183.846969                          183.892246\n",
      "3 2024-01-05                         182.975722                          183.109387                          183.180251\n",
      "4 2024-01-08                         183.644788                          183.669694                          183.688126\n"
     ]
    }
   ],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 4 - 6: EWM downside deviation (DD) in log scale with halflives(days) = 5, 10, 21 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature AMZN_downside_deviation_5 contains weird data\n",
      "Feature AMZN_downside_deviation_10 contains weird data\n",
      "Feature AMZN_downside_deviation_21 contains weird data\n",
      "Feature GOOGL_downside_deviation_5 contains weird data\n",
      "Feature GOOGL_downside_deviation_10 contains weird data\n",
      "Feature GOOGL_downside_deviation_21 contains weird data\n",
      "Feature MSFT_downside_deviation_5 contains weird data\n",
      "Feature MSFT_downside_deviation_10 contains weird data\n",
      "Feature MSFT_downside_deviation_21 contains weird data\n",
      "Feature NVDA_downside_deviation_5 contains weird data\n",
      "Feature NVDA_downside_deviation_10 contains weird data\n",
      "Feature NVDA_downside_deviation_21 contains weird data\n",
      "Feature AAPL_downside_deviation_5 contains weird data\n",
      "Feature AAPL_downside_deviation_10 contains weird data\n",
      "Feature AAPL_downside_deviation_21 contains weird data\n",
      "Feature NFLX_downside_deviation_5 contains weird data\n",
      "Feature NFLX_downside_deviation_10 contains weird data\n",
      "Feature NFLX_downside_deviation_21 contains weird data\n",
      "Feature AVGO_downside_deviation_5 contains weird data\n",
      "Feature AVGO_downside_deviation_10 contains weird data\n",
      "Feature AVGO_downside_deviation_21 contains weird data\n",
      "Feature TSLA_downside_deviation_5 contains weird data\n",
      "Feature TSLA_downside_deviation_10 contains weird data\n",
      "Feature TSLA_downside_deviation_21 contains weird data\n",
      "Feature META_downside_deviation_5 contains weird data\n",
      "Feature META_downside_deviation_10 contains weird data\n",
      "Feature META_downside_deviation_21 contains weird data\n",
      "Feature AMZN_downside_deviation_5 contains weird data\n",
      "Feature AMZN_downside_deviation_10 contains weird data\n",
      "Feature AMZN_downside_deviation_21 contains weird data\n",
      "Feature GOOGL_downside_deviation_5 contains weird data\n",
      "Feature GOOGL_downside_deviation_10 contains weird data\n",
      "Feature GOOGL_downside_deviation_21 contains weird data\n",
      "Feature MSFT_downside_deviation_5 contains weird data\n",
      "Feature MSFT_downside_deviation_10 contains weird data\n",
      "Feature MSFT_downside_deviation_21 contains weird data\n",
      "Feature NVDA_downside_deviation_5 contains weird data\n",
      "Feature NVDA_downside_deviation_10 contains weird data\n",
      "Feature NVDA_downside_deviation_21 contains weird data\n",
      "Feature AAPL_downside_deviation_5 contains weird data\n",
      "Feature AAPL_downside_deviation_10 contains weird data\n",
      "Feature AAPL_downside_deviation_21 contains weird data\n",
      "Feature NFLX_downside_deviation_5 contains weird data\n",
      "Feature NFLX_downside_deviation_10 contains weird data\n",
      "Feature NFLX_downside_deviation_21 contains weird data\n",
      "Feature AVGO_downside_deviation_5 contains weird data\n",
      "Feature AVGO_downside_deviation_10 contains weird data\n",
      "Feature AVGO_downside_deviation_21 contains weird data\n",
      "Feature TSLA_downside_deviation_5 contains weird data\n",
      "Feature TSLA_downside_deviation_10 contains weird data\n",
      "Feature TSLA_downside_deviation_21 contains weird data\n",
      "Feature META_downside_deviation_5 contains weird data\n",
      "Feature META_downside_deviation_10 contains weird data\n",
      "Feature META_downside_deviation_21 contains weird data\n"
     ]
    }
   ],
   "source": [
    "def weighted_moving_downside_deviation_with_log(data, halflives, TRADING_DAYS=252):\n",
    "    log_returns = np.log(data / data.shift(1))\n",
    "    downside_returns = log_returns[log_returns < 0].fillna(0)\n",
    "    ewm_std = downside_returns.ewm(halflife=halflives).std()\n",
    "    annualized_ewm_std = ewm_std * np.sqrt(TRADING_DAYS)\n",
    "    return annualized_ewm_std\n",
    "\n",
    "# Initialize a dictionary to store weird columns for each stock\n",
    "training_weird_columns_dict = {stock: [] for stock in stock_list}\n",
    "testing_weird_columns_dict = {stock: [] for stock in stock_list}\n",
    "\n",
    "# Training\n",
    "for stock in stock_list:\n",
    "    for halflife in [5, 10, 21]:\n",
    "        downside_deviation = weighted_moving_downside_deviation_with_log(training_stock_df[stock][stock], halflife)\n",
    "        downside_deviation = downside_deviation.reindex(training_stock_df[stock].index) \n",
    "        training_feature_df[stock][f'{stock}_downside_deviation_{halflife}'] = downside_deviation\n",
    "\n",
    "        if check_weird_data(training_feature_df[stock][f'{stock}_downside_deviation_{halflife}']):\n",
    "            print(f\"Feature {stock}_downside_deviation_{halflife} contains weird data\")\n",
    "            training_weird_columns_dict[stock].append(f'{stock}_downside_deviation_{halflife}')\n",
    "\n",
    "# Testing\n",
    "for stock in stock_list:\n",
    "    for halflife in [5, 10, 21]:\n",
    "        downside_deviation = weighted_moving_downside_deviation_with_log(testing_stock_df[stock][stock], halflife)\n",
    "        downside_deviation = downside_deviation.reindex(testing_stock_df[stock].index) \n",
    "        testing_feature_df[stock][f'{stock}_downside_deviation_{halflife}'] = downside_deviation\n",
    "\n",
    "        if check_weird_data(testing_feature_df[stock][f'{stock}_downside_deviation_{halflife}']):\n",
    "            print(f\"Feature {stock}_downside_deviation_{halflife} contains weird data\")\n",
    "            testing_weird_columns_dict[stock].append(f'{stock}_downside_deviation_{halflife}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle the weird data with KNN imputer\n",
    "def handle_weird_data_with_knn_imputer(data, weird_columns):\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    data[weird_columns] = imputer.fit_transform(data[weird_columns])\n",
    "    return data\n",
    "\n",
    "\n",
    "# Training\n",
    "for stock, weird_columns in training_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        training_feature_df[stock] = handle_weird_data_with_knn_imputer(training_feature_df[stock], weird_columns)\n",
    "\n",
    "# Testing\n",
    "for stock, weird_columns in testing_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        testing_feature_df[stock] = handle_weird_data_with_knn_imputer(testing_feature_df[stock], weird_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data again\n",
    "for stock, stock_data in training_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in training data\")\n",
    "\n",
    "for stock, stock_data in testing_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear weird_columns_dict, only clear the value, not the key\n",
    "for stock in stock_list:\n",
    "    training_weird_columns_dict[stock] = []\n",
    "\n",
    "for stock in stock_list:\n",
    "    testing_weird_columns_dict[stock] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  AAPL_exponential_moving_average_5  AAPL_exponential_moving_average_10  AAPL_exponential_moving_average_21  AAPL_downside_deviation_5  AAPL_downside_deviation_10  AAPL_downside_deviation_21\n",
      "0 2016-07-01                          23.972500                           23.972500                           23.972500                   0.176874                    0.186578                    0.195375\n",
      "1 2016-07-05                          23.852214                           23.856102                           23.858143                   0.176874                    0.186578                    0.195375\n",
      "2 2016-07-06                          23.863737                           23.865518                           23.866531                   0.176874                    0.186578                    0.195375\n",
      "3 2016-07-07                          23.900616                           23.898562                           23.897631                   0.176874                    0.186578                    0.195375\n",
      "4 2016-07-08                          23.970359                           23.960624                           23.955759                   0.176874                    0.186578                    0.195375\n",
      "        date  AAPL_exponential_moving_average_5  AAPL_exponential_moving_average_10  AAPL_exponential_moving_average_21  AAPL_downside_deviation_5  AAPL_downside_deviation_10  AAPL_downside_deviation_21\n",
      "0 2024-01-02                         185.639999                          185.639999                          185.639999                   0.133465                    0.133132                    0.129946\n",
      "1 2024-01-03                         184.896903                          184.920922                          184.933531                   0.133465                    0.133132                    0.129946\n",
      "2 2024-01-04                         183.760512                          183.846969                          183.892246                   0.059107                    0.059107                    0.059107\n",
      "3 2024-01-05                         182.975722                          183.109387                          183.180251                   0.072083                    0.071035                    0.070493\n",
      "4 2024-01-08                         183.644788                          183.669694                          183.688126                   0.133465                    0.133132                    0.129946\n"
     ]
    }
   ],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 7 - 9: Sortino ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN daily return contains weird data in training data\n",
      "GOOGL daily return contains weird data in training data\n",
      "MSFT daily return contains weird data in training data\n",
      "NVDA daily return contains weird data in training data\n",
      "AAPL daily return contains weird data in training data\n",
      "NFLX daily return contains weird data in training data\n",
      "AVGO daily return contains weird data in training data\n",
      "TSLA daily return contains weird data in training data\n",
      "META daily return contains weird data in training data\n",
      "AMZN daily return contains weird data in testing data\n",
      "GOOGL daily return contains weird data in testing data\n",
      "MSFT daily return contains weird data in testing data\n",
      "NVDA daily return contains weird data in testing data\n",
      "AAPL daily return contains weird data in testing data\n",
      "NFLX daily return contains weird data in testing data\n",
      "AVGO daily return contains weird data in testing data\n",
      "TSLA daily return contains weird data in testing data\n",
      "META daily return contains weird data in testing data\n"
     ]
    }
   ],
   "source": [
    "# First, calculate the daily return of the stock\n",
    "def daily_return(stock_price):\n",
    "    return stock_price.pct_change()\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    stock_data[f'{stock}_daily_return'] = daily_return(stock_data[stock])\n",
    "    if check_weird_data(stock_data[f'{stock}_daily_return']):\n",
    "            print(f\"{stock} daily return contains weird data in training data\")\n",
    "            training_weird_columns_dict[stock].append(f'{stock}_daily_return')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    stock_data[f'{stock}_daily_return'] = daily_return(stock_data[stock])\n",
    "    if check_weird_data(stock_data[f'{stock}_daily_return']):\n",
    "            print(f\"{stock} daily return contains weird data in testing data\")\n",
    "            testing_weird_columns_dict[stock].append(f'{stock}_daily_return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the weird data with KNN imputer\n",
    "# Training\n",
    "for stock, weird_columns in training_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        training_stock_df[stock] = handle_weird_data_with_knn_imputer(training_stock_df[stock], weird_columns)\n",
    "\n",
    "# Testing\n",
    "for stock, weird_columns in testing_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        testing_stock_df[stock] = handle_weird_data_with_knn_imputer(testing_stock_df[stock], weird_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data again\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in training data\")\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear weird_columns_dict\n",
    "for stock in stock_list: \n",
    "    training_weird_columns_dict[stock] = []\n",
    "    testing_weird_columns_dict[stock] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before calculating the Sortino ratio, \n",
    "# we need to append the daily risk free rate and \n",
    "# downside deviation to the stock data\n",
    "\n",
    "daily_risk_free_rate = pd.read_excel(f\"{DATA_DIR}/risk_free_rate/(Fama-French 3 Factors Plus Momentum - Daily Frequency)Risk-Free_Return_Rate.xlsx\")\n",
    "daily_risk_free_rate.rename(columns={'Risk-Free Return Rate (One Month Treasury Bill Rate)': 'daily_risk_free_rate'}, inplace=True)\n",
    "\n",
    "# Handle unmatched date format\n",
    "def parse_dates(date_series):\n",
    "    return pd.to_datetime(date_series, dayfirst=False)\n",
    "\n",
    "daily_risk_free_rate['date'] = parse_dates(daily_risk_free_rate['date'])\n",
    "\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    training_stock_df[stock] = pd.merge(stock_data, daily_risk_free_rate, on='date', how='inner')\n",
    "    for halflife in [5, 10, 21]:\n",
    "        downside_deviation = training_feature_df[stock][['date', f'{stock}_downside_deviation_{halflife}']]\n",
    "        training_stock_df[stock] = pd.merge(training_stock_df[stock], downside_deviation, on='date', how='inner')\n",
    "\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    testing_stock_df[stock] = pd.merge(stock_data, daily_risk_free_rate, on='date', how='inner')\n",
    "    for halflife in [5, 10, 21]:\n",
    "        downside_deviation = testing_feature_df[stock][['date', f'{stock}_downside_deviation_{halflife}']]\n",
    "        testing_stock_df[stock] = pd.merge(testing_stock_df[stock], downside_deviation, on='date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Sortino ratio\n",
    "def sortino_ratio(daily_return, risk_free_rate, downside_deviation):\n",
    "    return (daily_return - risk_free_rate) / downside_deviation\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    for halflife in [5, 10, 21]:\n",
    "        daily_return = stock_data[f'{stock}_daily_return']\n",
    "        risk_free_rate = stock_data['daily_risk_free_rate']\n",
    "        downside_deviation = stock_data[f'{stock}_downside_deviation_{halflife}']\n",
    "        training_feature_df[stock][f'{stock}_sortino_ratio_{halflife}'] = sortino_ratio(daily_return, risk_free_rate, downside_deviation)\n",
    "\n",
    "        if check_weird_data(training_feature_df[stock][f'{stock}_sortino_ratio_{halflife}']):\n",
    "            print(f\"{stock} sortino ratio {halflife} contains weird data in training data\")\n",
    "            training_weird_columns_dict[stock].append(f'{stock}_sortino_ratio_{halflife}')\n",
    "\n",
    "# Testing\n",
    "for stock, stock_data in testing_stock_df.items():\n",
    "    for halflife in [5, 10, 21]:\n",
    "        daily_return = stock_data[f'{stock}_daily_return']\n",
    "        risk_free_rate = stock_data['daily_risk_free_rate']\n",
    "        downside_deviation = stock_data[f'{stock}_downside_deviation_{halflife}']\n",
    "        testing_feature_df[stock][f'{stock}_sortino_ratio_{halflife}'] = sortino_ratio(daily_return, risk_free_rate, downside_deviation)\n",
    "\n",
    "        if check_weird_data(testing_feature_df[stock][f'{stock}_sortino_ratio_{halflife}']):\n",
    "            print(f\"{stock} sortino ratio {halflife} contains weird data in testing data\")\n",
    "            testing_weird_columns_dict[stock].append(f'{stock}_sortino_ratio_{halflife}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  AAPL_exponential_moving_average_5  AAPL_exponential_moving_average_10  AAPL_exponential_moving_average_21  AAPL_downside_deviation_5  AAPL_downside_deviation_10  AAPL_downside_deviation_21  AAPL_sortino_ratio_5  AAPL_sortino_ratio_10  AAPL_sortino_ratio_21\n",
      "0 2016-07-01                          23.972500                           23.972500                           23.972500                   0.176874                    0.186578                    0.195375              0.007167               0.006794               0.006488\n",
      "1 2016-07-05                          23.852214                           23.856102                           23.858143                   0.176874                    0.186578                    0.195375             -0.053121              -0.050358              -0.048091\n",
      "2 2016-07-06                          23.863737                           23.865518                           23.866531                   0.176874                    0.186578                    0.195375              0.032084               0.030415               0.029046\n",
      "3 2016-07-07                          23.900616                           23.898562                           23.897631                   0.176874                    0.186578                    0.195375              0.024209               0.022950               0.021916\n",
      "4 2016-07-08                          23.970359                           23.960624                           23.955759                   0.176874                    0.186578                    0.195375              0.043552               0.041286               0.039427\n",
      "        date  AAPL_exponential_moving_average_5  AAPL_exponential_moving_average_10  AAPL_exponential_moving_average_21  AAPL_downside_deviation_5  AAPL_downside_deviation_10  AAPL_downside_deviation_21  AAPL_sortino_ratio_5  AAPL_sortino_ratio_10  AAPL_sortino_ratio_21\n",
      "0 2024-01-02                         185.639999                          185.639999                          185.639999                   0.133465                    0.133132                    0.129946              0.008283               0.008304               0.008507\n",
      "1 2024-01-03                         184.896903                          184.920922                          184.933531                   0.133465                    0.133132                    0.129946             -0.057750              -0.057895              -0.059314\n",
      "2 2024-01-04                         183.760512                          183.846969                          183.892246                   0.059107                    0.059107                    0.059107             -0.218589              -0.218589              -0.218589\n",
      "3 2024-01-05                         182.975722                          183.109387                          183.180251                   0.072083                    0.071035                    0.070493             -0.058725              -0.059591              -0.060049\n",
      "4 2024-01-08                         183.644788                          183.669694                          183.688126                   0.133465                    0.133132                    0.129946              0.179485               0.179934               0.184345\n"
     ]
    }
   ],
   "source": [
    "# Print the result to ensure the data is correct\n",
    "print(training_feature_df['AAPL'].head().to_string())\n",
    "print(testing_feature_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date        AAPL  AAPL_daily_return  daily_risk_free_rate  AAPL_downside_deviation_5  AAPL_downside_deviation_10  AAPL_downside_deviation_21\n",
      "0 2024-01-02  185.639999           0.001325               0.00022                   0.133465                    0.133132                    0.129946\n",
      "1 2024-01-03  184.250000          -0.007488               0.00022                   0.133465                    0.133132                    0.129946\n",
      "2 2024-01-04  181.910004          -0.012700               0.00022                   0.059107                    0.059107                    0.059107\n",
      "3 2024-01-05  181.179993          -0.004013               0.00022                   0.072083                    0.071035                    0.070493\n",
      "4 2024-01-08  185.559998           0.024175               0.00022                   0.133465                    0.133132                    0.129946\n",
      "        date       AAPL  AAPL_daily_return  daily_risk_free_rate  AAPL_downside_deviation_5  AAPL_downside_deviation_10  AAPL_downside_deviation_21\n",
      "0 2016-07-01  23.972500           0.001278               0.00001                   0.176874                    0.186578                    0.195375\n",
      "1 2016-07-05  23.747499          -0.009386               0.00001                   0.176874                    0.186578                    0.195375\n",
      "2 2016-07-06  23.882500           0.005685               0.00001                   0.176874                    0.186578                    0.195375\n",
      "3 2016-07-07  23.985001           0.004292               0.00001                   0.176874                    0.186578                    0.195375\n",
      "4 2016-07-08  24.170000           0.007713               0.00001                   0.176874                    0.186578                    0.195375\n"
     ]
    }
   ],
   "source": [
    "print(testing_stock_df['AAPL'].head().to_string())\n",
    "print(training_stock_df['AAPL'].head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature AMZN_mom12m contains weird data in training data\n",
      "Feature GOOGL_mom12m contains weird data in training data\n",
      "Feature MSFT_mom12m contains weird data in training data\n",
      "Feature NVDA_mom12m contains weird data in training data\n",
      "Feature AAPL_mom12m contains weird data in training data\n",
      "Feature NFLX_mom12m contains weird data in training data\n",
      "Feature AVGO_mom12m contains weird data in training data\n",
      "Feature TSLA_mom12m contains weird data in training data\n",
      "Feature META_mom12m contains weird data in training data\n"
     ]
    }
   ],
   "source": [
    "def momentum_12m(stock_price):\n",
    "    price_1m_ago = stock_price.shift(21)\n",
    "    price_12m_ago = stock_price.shift(252)\n",
    "    return price_1m_ago / price_12m_ago - 1\n",
    "\n",
    "# Training\n",
    "for stock, stock_data in training_stock_df.items():\n",
    "    training_feature_df[stock][f'{stock}_mom12m'] = momentum_12m(stock_data[stock])\n",
    "    if check_weird_data(training_feature_df[stock][f'{stock}_mom12m']):\n",
    "        print(f\"Feature {stock}_mom12m contains weird data in training data\")\n",
    "        training_weird_columns_dict[stock].append(f'{stock}_mom12m')\n",
    "\n",
    "# Notice that the testing period is too short to calculate the 12-month momentum\n",
    "# So it will be calculated in later stage if this feature is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for stock, weird_columns in training_weird_columns_dict.items():\n",
    "    if weird_columns:\n",
    "        training_feature_df[stock] = handle_weird_data_with_knn_imputer(training_feature_df[stock], weird_columns)\n",
    "\n",
    "# Check the data again\n",
    "for stock, stock_data in training_feature_df.items():\n",
    "    if check_weird_data(stock_data):\n",
    "        print(f\"The {stock} stock price data still contains weird data in training data\")\n",
    "\n",
    "# Clear weird_columns_dict\n",
    "for stock in stock_list:\n",
    "    training_weird_columns_dict[stock] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature 11: short-term reversal (mom1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature AMZN_mom1m contains weird data in training data\n",
      "Feature GOOGL_mom1m contains weird data in training data\n",
      "Feature MSFT_mom1m contains weird data in training data\n",
      "Feature NVDA_mom1m contains weird data in training data\n",
      "Feature AAPL_mom1m contains weird data in train